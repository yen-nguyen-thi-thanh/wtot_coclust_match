{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####========================#####\n",
    "#####        WTOT-matching v1.0 #####\n",
    "#####        WTOT-coclust v1.0       #####\n",
    "#####======================#####\n",
    "# Application: This repository contains python and R codes to run the algorithms WTOT-matching and WTOT-coclust, as presented in the paper Optimal transport-based machine learning to match specific patterns: application to the detection of molecular regulation patterns in omics data by T. T. Y. Nguyen, W. Harchaoui, L. Mégret, C. Mendoza, O. Bouaziz, C. Neri, A. Chambaz (2024). The paper can be found .\n",
    "# The aim of WTOT-matching and WTOT-coclust is to learn a pattern of correspondence between two datasets in situations where it is desirable to match elements that exhibit an affine relationship (our approach accommodates any relationship, not necessarily affine, as long as it can be parametrized). In the motivating case-study, the challenge is to better understand micro-RNA regulation in Huntington's disease model mice.\n",
    "# The algorithms unfold in two stages. During the first stage, an optimal transport plan P and an optimal affine transformation are learned, using the Sinkhorn algorithm and a mini-batch gradient descent. During the second stage, P is exploited to derive either several co-clusters (WTOT-coclust) or several sets of matched elements (WTOT-matching).\n",
    "\n",
    "# The Jupyter notebook `WTOT_MC_demo.ipynb` presents several illustrations. \n",
    "\n",
    "# The main files of the repository are:\n",
    "# - `utils.py`: defines key-functions used during the first stage of the algorithms to compute the optimal transport matrix *P*, kernel, mapping, the squared Euclidean distance and the best number of coclusters;\n",
    "# - `wtot.py`: it is the core code implementing the first stage of the algorithms;\n",
    "# - `match_coclust.py`: it is the core code of the second stage of the algorithms. \n",
    "\n",
    "# The folder `simulations` contains the codes used to generate data for the experimantal study presented in the paper. The folder `datasets` contains the miRNA and mRNA data obtained in the striatum and cortex of the HD model mice; and the results obtained by running the WTOT-matching and WTOT-coclust. The file `sample_A4.npz` is a synthetic dataset generated in configuration A4 of the simulation study (see Section 5 of the paper). \n",
    "\n",
    "#\n",
    "# Version: WTOT-matching v1.0 ; WTOT-coclust v1.0\n",
    "# Date: 15 April 2020\n",
    "#\n",
    "# Contributors (alphabetic order): O. Bouaziz (1), A. Chambaz (1), W. Harchaoui (1), L. Mégret (2), C. Mendoza (2), C. Neri (2), T. T. Y. Nguyen (1) #\n",
    "# Laboratory:\n",
    "#   (1) MAP5, F-75006 Paris, France\n",
    "#   (2) UMR CNRS 8256, Team Brain-C Lab, F-75005 Paris, France\n",
    "#\n",
    "# Affiliations:\n",
    "#   (1) Université Paris Cité, CNRS\n",
    "#   (2) Sorbonne Université, CNRS\n",
    "#\n",
    "#####=================================================================#####\n",
    "#####       Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International license          #####\n",
    "#####=============================================================#####\n",
    "#####               Copyright (C) T. T. Y. Nguyen, W. Harchaoui, L. Mégret, C. Mendoza, O. Bouaziz, C. Neri, A. Chambaz (1) #####\n",
    "#####                       Christian Neri(christian.neri@inserm.fr) Antoine Chambaz(antoine.chambaz@u-paris.fr) 2024                               #####\n",
    "#####========================#####\n",
    "#      \n",
    "#      This work is licensed under the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 \n",
    "#      International License. To view a copy of this license, visit \n",
    "#      http://creativecommons.org/licenses/by-nc-nd/4.0/ or send a letter to \n",
    "#      Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n",
    "#      \n",
    "#####======================#####\n",
    "#####=====================#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal transport-based machine learning to match specific expression patterns in omics data\n",
    "\n",
    "\n",
    "In this notebook, we will show how to use (a) optimal transport and (b) matching or co-clustering procedures to match two data sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore this cell if the corresponding packages are already installed\n",
    "\n",
    "#!pip install coclust\n",
    "#!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from wtot import wtot\n",
    "from match_coclust import matching, SCC1_star, SCC1, SCC2_star, SCC2\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Real data \n",
    "\n",
    "The real data set has been kindly made public by Langfelder et al. (see their articles published in [Nature Neuroscience](https://europepmc.org/article/med/26900923) and [Plos One](https://pubmed.ncbi.nlm.nih.gov/29324753/)).\n",
    "\n",
    "## Data loading\n",
    "\n",
    "Load the real data then convert to matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_micro = pd.read_csv('./datasets/LFC_Cortex_mirna.txt', sep = ' ', delimiter = '\\t') \n",
    "data_mess = pd.read_csv('./datasets/LFC_Cortex_mrna.txt', sep = ' ', delimiter = '\\t')\n",
    "\n",
    "x = data_micro.values\n",
    "y = data_mess.values\n",
    "\n",
    "x = x[:200,:3]\n",
    "y = y[: 200,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameter\n",
    "m = 1\n",
    "n = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm WTOT_matching and WTOT_coclust\n",
    "### First step ( WTOT_...)\n",
    "\n",
    "We compute the optimal transport matrix, optimal transformation and an estimator of the \"weights\" (see paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = wtot(x, y, m = 1, n = 3, batch_size_x = 64 , batch_size_y = 64)\n",
    "\n",
    "# value of the optimal transport matrix, the optimal transformation, and the \"weights\".\n",
    "pi_np = results['P'] \n",
    "theta = results['theta']\n",
    "w = results['w']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second step \n",
    "#### Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_match = matching(pi_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The indices of the miRNAs associated to the first mRNA of the list: {0, 100, 71, 72, 105, 169, 171, 12, 177, 122, 156} .\n",
      "\n",
      "The indices of the mRNAs associated to the first miRNA of the list: [0, 13, 45, 47, 63, 64, 66, 70, 78, 79, 101, 119, 141, 155, 167, 173, 176, 177, 195] .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the collection calM\n",
    "N_m = results_match['N_m']\n",
    "print('The indices of the miRNAs associated to the first mRNA of the list:', N_m[0], '.\\n')\n",
    "# the collection calN\n",
    "M_n = results_match['M_n']\n",
    "print('The indices of the mRNAs associated to the first miRNA of the list:', M_n[0], '.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Co-clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WTOT-SCC1\n",
    "SCC1_res = SCC1(pi_np)\n",
    "\n",
    "### WTOT-SCC1*\n",
    "SCC1_star_res = SCC1_star(pi_np, 4 )\n",
    "\n",
    "### WTOT-SCC2\n",
    "SCC2_res = SCC2(pi_np)\n",
    "\n",
    "### WTOT-SCC*\n",
    "SCC2_star_res = SCC2_star(pi_np, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: synthetic data\n",
    "\n",
    "We now present an illustration based on simulated data.\n",
    "\n",
    "## Data simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### an example of synthesic data\n",
    "datas = np.load('./datasets/sample_A4.npz', allow_pickle = True) # the configuration A4 of the first simulation study\n",
    "datas = datas['dats']\n",
    "\n",
    "id_sample = 1\n",
    "x         = datas[id_sample]['x']\n",
    "y         = datas[id_sample]['y']\n",
    "labels_x  = datas[id_sample]['labels_x']\n",
    "labels_y  = datas[id_sample]['labels_y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First step ( WTOT_...)\n",
    "We compute the optimal transport matrix, optimal transformation and an estimator of the \"weights\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = wtot(x, y, m = 2, n=1, batch_size_x = 64, batch_size_y = 64)\n",
    "\n",
    "# value of the optimal transport matrix, the optimal transformation, and the \"weights\"\n",
    "pi_np = results['P'] \n",
    "theta = results['theta']\n",
    "w = results['w']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second step \n",
    "#### Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_match = matching(pi_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The indices of the columns associated to the first row: {290, 294, 166, 204, 205, 239, 112, 50, 243, 277, 86, 22, 249, 187} .\n",
      "\n",
      "The indices of rows associated to the first column [74, 110, 111, 145, 178, 211, 278, 286, 293] .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the collection of calM\n",
    "N_m = results_match['N_m']\n",
    "print('The indices of the columns associated to the first row:', N_m[0], '.\\n')\n",
    "# the collection of calN\n",
    "M_n = results_match['M_n']\n",
    "print('The indices of rows associated to the first column', M_n[0], '.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Co-clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### WTOT-SCC1\n",
    "SCC1_res = SCC1(pi_np)\n",
    "### WTOT-SCC1*\n",
    "SCC1_star_res =SCC1_star(pi_np, 4 )\n",
    "### WTOT-SCC2\n",
    "SCC2_res = SCC2(pi_np)\n",
    "### WTOT-SCC*\n",
    "SCC2_star_res = SCC2_star(pi_np, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
